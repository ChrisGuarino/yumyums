{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisguarino/opt/anaconda3/envs/yumyums_env3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-05 11:23:00.740 python[56851:2506038] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0168, 0.0180, 0.9652]])\n",
      "tensor([[0.0136, 0.0169, 0.9695]])\n",
      "tensor([[0.0141, 0.0167, 0.9692]])\n",
      "tensor([[0.0143, 0.0151, 0.9707]])\n",
      "tensor([[0.0139, 0.0153, 0.9708]])\n",
      "tensor([[0.0142, 0.0146, 0.9713]])\n",
      "tensor([[0.0143, 0.0159, 0.9698]])\n",
      "tensor([[0.0139, 0.0158, 0.9703]])\n",
      "tensor([[0.0135, 0.0149, 0.9717]])\n",
      "tensor([[0.0140, 0.0148, 0.9713]])\n",
      "tensor([[0.0140, 0.0165, 0.9695]])\n",
      "tensor([[0.0135, 0.0160, 0.9704]])\n",
      "tensor([[0.0139, 0.0178, 0.9683]])\n",
      "tensor([[0.0141, 0.0168, 0.9691]])\n",
      "tensor([[0.0138, 0.0159, 0.9702]])\n",
      "tensor([[0.0153, 0.0156, 0.9691]])\n",
      "tensor([[0.0146, 0.0170, 0.9685]])\n",
      "tensor([[0.0140, 0.0169, 0.9691]])\n",
      "tensor([[0.0140, 0.0175, 0.9685]])\n",
      "tensor([[0.0141, 0.0165, 0.9694]])\n",
      "tensor([[0.0137, 0.0150, 0.9712]])\n",
      "tensor([[0.0136, 0.0155, 0.9709]])\n",
      "tensor([[0.0132, 0.0159, 0.9709]])\n",
      "tensor([[0.0133, 0.0185, 0.9682]])\n",
      "tensor([[0.0134, 0.0163, 0.9703]])\n",
      "tensor([[0.0127, 0.0177, 0.9696]])\n",
      "tensor([[0.0129, 0.0150, 0.9721]])\n",
      "tensor([[0.0133, 0.0161, 0.9705]])\n",
      "tensor([[0.0142, 0.0158, 0.9700]])\n",
      "tensor([[0.0129, 0.0179, 0.9693]])\n",
      "tensor([[0.0137, 0.0165, 0.9698]])\n",
      "tensor([[0.0139, 0.0156, 0.9705]])\n",
      "tensor([[0.0138, 0.0153, 0.9709]])\n",
      "tensor([[0.0135, 0.0150, 0.9715]])\n",
      "tensor([[0.0136, 0.0145, 0.9719]])\n",
      "tensor([[0.0136, 0.0145, 0.9719]])\n",
      "tensor([[0.0132, 0.0145, 0.9723]])\n",
      "tensor([[0.0130, 0.0145, 0.9725]])\n",
      "tensor([[0.0128, 0.0141, 0.9731]])\n",
      "tensor([[0.0129, 0.0140, 0.9731]])\n",
      "tensor([[0.0128, 0.0140, 0.9732]])\n",
      "tensor([[0.0128, 0.0141, 0.9731]])\n",
      "tensor([[0.0128, 0.0138, 0.9734]])\n",
      "tensor([[0.0128, 0.0135, 0.9737]])\n",
      "tensor([[0.0126, 0.0133, 0.9741]])\n",
      "tensor([[0.0126, 0.0135, 0.9739]])\n",
      "tensor([[0.0126, 0.0137, 0.9738]])\n",
      "tensor([[0.0125, 0.0135, 0.9740]])\n",
      "tensor([[0.0126, 0.0136, 0.9739]])\n",
      "tensor([[0.0124, 0.0134, 0.9742]])\n",
      "tensor([[0.0124, 0.0136, 0.9741]])\n",
      "tensor([[0.0125, 0.0140, 0.9735]])\n",
      "tensor([[0.0124, 0.0136, 0.9740]])\n",
      "tensor([[0.0124, 0.0137, 0.9739]])\n",
      "tensor([[0.0127, 0.0138, 0.9735]])\n",
      "tensor([[0.0129, 0.0150, 0.9721]])\n",
      "tensor([[0.0129, 0.0162, 0.9709]])\n",
      "tensor([[0.0128, 0.0170, 0.9702]])\n",
      "tensor([[0.0137, 0.0157, 0.9707]])\n",
      "tensor([[0.0133, 0.0169, 0.9698]])\n",
      "tensor([[0.0126, 0.0173, 0.9701]])\n",
      "tensor([[0.0129, 0.0158, 0.9713]])\n",
      "tensor([[0.0135, 0.0158, 0.9707]])\n",
      "tensor([[0.0133, 0.0159, 0.9708]])\n",
      "tensor([[0.0132, 0.0153, 0.9716]])\n",
      "tensor([[0.0136, 0.0162, 0.9702]])\n",
      "tensor([[0.0139, 0.0158, 0.9703]])\n",
      "tensor([[0.0143, 0.0158, 0.9699]])\n",
      "tensor([[0.0138, 0.0161, 0.9700]])\n",
      "tensor([[0.0143, 0.0162, 0.9695]])\n",
      "tensor([[0.0141, 0.0159, 0.9700]])\n",
      "tensor([[0.0131, 0.0161, 0.9708]])\n",
      "tensor([[0.0136, 0.0162, 0.9701]])\n",
      "tensor([[0.0137, 0.0154, 0.9709]])\n",
      "tensor([[0.0144, 0.0157, 0.9699]])\n",
      "tensor([[0.0152, 0.0150, 0.9698]])\n",
      "tensor([[0.0148, 0.0153, 0.9699]])\n",
      "tensor([[0.0137, 0.0175, 0.9687]])\n",
      "tensor([[0.0134, 0.0192, 0.9674]])\n",
      "tensor([[0.0127, 0.0160, 0.9713]])\n",
      "tensor([[0.0127, 0.0151, 0.9722]])\n",
      "tensor([[0.0142, 0.0171, 0.9687]])\n",
      "tensor([[0.0127, 0.0170, 0.9703]])\n",
      "tensor([[0.0122, 0.0147, 0.9731]])\n",
      "tensor([[0.0126, 0.0179, 0.9696]])\n",
      "tensor([[0.0163, 0.0152, 0.9685]])\n",
      "tensor([[0.0144, 0.0131, 0.9725]])\n",
      "tensor([[0.0142, 0.0143, 0.9715]])\n",
      "tensor([[0.0168, 0.0141, 0.9691]])\n",
      "tensor([[0.0137, 0.0134, 0.9729]])\n",
      "tensor([[0.0139, 0.0140, 0.9721]])\n",
      "tensor([[0.0138, 0.0142, 0.9720]])\n",
      "tensor([[0.0135, 0.0137, 0.9728]])\n",
      "tensor([[0.0151, 0.0135, 0.9715]])\n",
      "tensor([[0.0160, 0.0128, 0.9712]])\n",
      "tensor([[0.0159, 0.0131, 0.9710]])\n",
      "tensor([[0.0162, 0.0142, 0.9697]])\n",
      "tensor([[0.0163, 0.0149, 0.9688]])\n",
      "tensor([[0.0154, 0.0150, 0.9697]])\n",
      "tensor([[0.0172, 0.0172, 0.9656]])\n",
      "tensor([[0.0183, 0.0177, 0.9640]])\n",
      "tensor([[0.0180, 0.0173, 0.9647]])\n",
      "tensor([[0.0178, 0.0158, 0.9664]])\n",
      "tensor([[0.0178, 0.0165, 0.9657]])\n",
      "tensor([[0.0182, 0.0163, 0.9655]])\n",
      "tensor([[0.0196, 0.0160, 0.9645]])\n",
      "tensor([[0.0183, 0.0163, 0.9653]])\n",
      "tensor([[0.0180, 0.0163, 0.9657]])\n",
      "tensor([[0.0182, 0.0168, 0.9650]])\n",
      "tensor([[0.0182, 0.0163, 0.9654]])\n",
      "tensor([[0.0192, 0.0183, 0.9625]])\n",
      "tensor([[0.0196, 0.0178, 0.9625]])\n",
      "tensor([[0.0202, 0.0190, 0.9608]])\n",
      "tensor([[0.0209, 0.0196, 0.9595]])\n",
      "tensor([[0.0212, 0.0189, 0.9599]])\n",
      "tensor([[0.0214, 0.0187, 0.9599]])\n",
      "tensor([[0.0206, 0.0232, 0.9562]])\n",
      "tensor([[0.0216, 0.0227, 0.9557]])\n",
      "tensor([[0.0214, 0.0237, 0.9549]])\n",
      "tensor([[0.0206, 0.0183, 0.9611]])\n",
      "tensor([[0.0204, 0.0173, 0.9623]])\n",
      "tensor([[0.0196, 0.0180, 0.9624]])\n",
      "tensor([[0.0202, 0.0190, 0.9608]])\n",
      "tensor([[0.0197, 0.0194, 0.9610]])\n",
      "tensor([[0.0196, 0.0186, 0.9617]])\n",
      "tensor([[0.0190, 0.0183, 0.9627]])\n",
      "tensor([[0.0216, 0.0181, 0.9603]])\n",
      "tensor([[0.0174, 0.0178, 0.9648]])\n",
      "tensor([[0.0171, 0.0168, 0.9661]])\n",
      "tensor([[0.0178, 0.0166, 0.9656]])\n",
      "tensor([[0.0306, 0.0210, 0.9483]])\n",
      "tensor([[0.0199, 0.0168, 0.9633]])\n",
      "tensor([[0.0220, 0.0179, 0.9601]])\n",
      "tensor([[0.0194, 0.0171, 0.9635]])\n",
      "tensor([[0.0253, 0.0204, 0.9542]])\n",
      "tensor([[0.0209, 0.0161, 0.9629]])\n",
      "tensor([[0.0192, 0.0164, 0.9643]])\n",
      "tensor([[0.0180, 0.0163, 0.9657]])\n",
      "tensor([[0.0171, 0.0160, 0.9669]])\n",
      "tensor([[0.0169, 0.0165, 0.9666]])\n",
      "tensor([[0.0168, 0.0166, 0.9666]])\n",
      "tensor([[0.0168, 0.0164, 0.9668]])\n",
      "tensor([[0.0171, 0.0173, 0.9656]])\n",
      "tensor([[0.0174, 0.0170, 0.9656]])\n",
      "tensor([[0.0172, 0.0160, 0.9668]])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "\n",
    "# Initialize the image processor and model\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained('ChrisGuarino/model')  # Replace with your model\n",
    "model.eval()\n",
    "\n",
    "# Define your class labels\n",
    "class_labels = ['Prim', 'Rupe', 'No Cat']  # Replace with your actual labels\n",
    "\n",
    "# Start the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Confidence Threshold\n",
    "confidence_threshold = .8  # Define a threshold\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # Preprocess the frame\n",
    "        frame_resized = cv2.resize(frame, (244, 244))\n",
    "        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "        inputs = processor(images=frame_rgb, return_tensors=\"pt\")\n",
    "\n",
    "        # Get predicti?ons\n",
    "        with torch.no_grad():\n",
    "            predictions = model(**inputs).logits\n",
    "\n",
    "            # Convert predictions to probabilities and get the highest probability class\n",
    "            probabilities = torch.nn.functional.softmax(predictions, dim=-1)\n",
    "            confidences, predicted_class_idx = torch.max(probabilities, dim=-1)\n",
    "            predicted_class = class_labels[predicted_class_idx]#Something with +1 to shift the labels if we add a No Cat label\n",
    "        print(probabilities)\n",
    "\n",
    "        # Check if confidence is above the threshold\n",
    "        if confidences.item() < confidence_threshold:\n",
    "            label = 'No Cat'\n",
    "            confidence = 0\n",
    "        else:\n",
    "            label = class_labels[predicted_class_idx.item()]  # +1 to account for 'No Cat'\n",
    "            confidence = confidences.item()\n",
    "\n",
    "        # Prepare the display text\n",
    "        display_text = f'{label} ({confidence:.2f})'\n",
    "\n",
    "        # Display the prediction on the frame\n",
    "        cv2.putText(frame_resized, display_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame', frame_resized)\n",
    "\n",
    "        # Break the loop with 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the capture when done\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
